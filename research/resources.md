List of research material used in the various models.

## Word Embeddings:

1. [Stanford's GLoVe Projects](https://nlp.stanford.edu/projects/glove/)
2. [Word2Vec Tensorflow Implementation](https://www.tensorflow.org/tutorials/word2vec)
3. [Original Word2Vec Paper](http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)
4. [Follow-up Doc2Vec Paper](https://arxiv.org/pdf/1405.4053.pdf)
5. [Blog on porting Word2Vec to Python](https://rare-technologies.com/deep-learning-with-word2vec-and-gensim/)
6. [Gensim's Word2Vec API Docs](https://radimrehurek.com/gensim/models/word2vec.html)
7. [Gensim's Stored Vector API Docs](https://radimrehurek.com/gensim/models/keyedvectors.html)

## Generative LSTM Language Models

1. [Mikolov Paper on RNN Based Language Model](http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf)
2. [Karpathy's character level RNN blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)

## Other Research

1. [Globally Coherent Text Generation with Nerual Checklist Models](https://homes.cs.washington.edu/~yejin/Papers/emnlp16_neuralchecklist.pdf)
2. [Sequence-to-sequence models in Tensorflow](https://www.tensorflow.org/tutorials/seq2seq)
3. [Generating Inference Chains](https://arxiv.org/pdf/1606.01404.pdf)